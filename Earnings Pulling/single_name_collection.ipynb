{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing delta probability for weeklies and monthlies\\n\",\n",
    "    - Does delta match probability of occurrence\\n\",\n",
    "    - Check Kelly criterion for long straddles/delta neutral back ratios\\n\",\n",
    "        - To calculate expected losses and gains, use options pricing module to interpolate prices at given percentage\\n\",\n",
    "        moves and use the normal pdf as the probability weightings\\n\n",
    "Check earnings returns post announcement factors\\n\",\n",
    "    - Factors:\\n\",\n",
    "        - Number of times beaten earnings (Dummy Variable)\\n\",\n",
    "        - Consecutive earnings beats\\n\",\n",
    "        - Consecutive earnings upsets\\n\",\n",
    "        - 3 Month Trend before earnings\\n\",\n",
    "        - YTD Trend\\n\",\n",
    "        - Momentum of monthly returns (20 day, 60 day)\\n\"\n",
    "        \n",
    "        \n",
    "price-to-book (P / B), price-to-earnings (P / E), price-to-free cashflow (P / FCF) and enterprise value-to-EBITDA (EV / EBITDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_datareader.data import Options\n",
    "from py_vollib.black_scholes_merton.implied_volatility import *\n",
    "# ts = TimeSeries(key='5HZEUI5AFJB06BUK',output_format='pandas')\n",
    "import py_vollib\n",
    "from py_vollib.black_scholes_merton.implied_volatility import *\n",
    "from py_vollib.black_scholes_merton.greeks.analytical import *\n",
    "import plotly\n",
    "import os\n",
    "import pandas_market_calendars as mcal\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import urllib.request as req\n",
    "import time\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "from helpers import *\n",
    "from tickers import tickers\n",
    "\n",
    "from scipy.stats import norm as norm\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "from openpyxl import load_workbook\n",
    "from yahoo_query import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# functions list:\n",
    "\n",
    "#     maturities(dt.datetime()) --> [float(front_wgt), float(back_wgt)]\n",
    "\n",
    "#     optionslam_scrape(str[ticker]) --> dict[earnings]\n",
    "\n",
    "#     yahoo_table_parse(str[raw_html_table]) --> DataFrame[ticker]\n",
    "\n",
    "#     yahoo_earnings(dt.datetime()) --> DataFrame[earnings_on_date]\n",
    "\n",
    "#     fundamentals(str[ticker]) --> DataFrame[stock_fundamentals]\n",
    "\n",
    "#     get_fundas(list[ticker_lst]) --> DataFrame[stock_fundamentals]\n",
    "\n",
    "#     historical_data(str[ticker], int[day_number], int[rolling_window], outsize[str]) --> DataFrame[daily_stock_data]\n",
    "\n",
    "#     current_volatility(list[ticker_lst], int[roll]) --> DataFrame[stock_volatilities]\n",
    "\n",
    "#     all_options(str[ticker], bool[greeks]) --> DataFrame[options_chains]\n",
    "\n",
    "#     earnings_condor(str[ticker], int[max_gap], int[dte_thresh], float[|money_thresh| <= 1]) -- DataFrame[condors], DataFrame[puts], DataFrame[calls]\n",
    "\n",
    "#     write_excel(str[filename], list[str[sheetnames]], list[dataframes]) --> void()\n",
    "\n",
    "#     curr_stock_data(str[ticker]) --> DataFrame[stock_info]\n",
    "\n",
    "#     curr_batch_quotes(list_of_string[tickers]) --> DataFrame[stock_info]\n",
    "\n",
    "#     past_earnings(str[ticker]) --> DataFrame[earnings_info]\n",
    "\n",
    "#     earnings_history(str[ticker]) --> [DataFrame[earnings_estimate], DataFrame[past_earnings], DataFrame[earnings_estimate_change]]\n",
    "\n",
    "#     av_data(str[ticker]) --> DataFrame[ticker_open, ticker_close]\n",
    "\n",
    "#     av_batch(list_of_str[tickers]) --> DataFrame[tickers_closes]\n",
    "\n",
    "#     check_mkt_corr(int[corr_rolling_window],int[plot_window]) --> DataFrame[rolling_corr]\n",
    "\n",
    "#     vvix_check() --> DataFrame[VVIX Data]\n",
    "\n",
    "#     earnings_longs(list_of_str[ticker], float[bid_ask_spread]) --> DataFrame[option_chains]\n",
    "\n",
    "#     all_options_v2(str[ticker], int[dte_ub], int[dte_lb], float[moneyness]) --> DataFrame[option_chains]\n",
    "\n",
    "#     yahoo_options_query(str[ticker], int[dte_ub], int[dte_lb]) --> DataFrame[option_chains]\n",
    "\n",
    "#     greek_calc(DataFrame[option_chain], str[prem_price_use], str[day_format], float[interest_rate], float[dividend_rate])\n",
    "\n",
    "#     price_sim(DataFrame[options_df], float[price_change], float[vol_change], int[days_change], str[output = 'All'],\n",
    "#               str[skew = 'flat'], str[day_format = 'trading'], float[interest_rate = 0.0193], float[dividend_rate = 0],\n",
    "#               float[prem_price_use = 'Mid'])\n",
    "\n",
    "\n",
    "#     position_sim(DataFrame[position_df], list_of_int[holdings], int[shares],\n",
    "#                  float[price_change], float[vol_change], int[dte_change], str[output = 'All'],\n",
    "#                  str[skew = 'flat'], str[prem_price_use = 'Mid'], str[day_format = 'trading'], \n",
    "#                  float[interest_rate = 0.0193], float[dividend_rate = 0])\n",
    "\n",
    "#     yahoo_fundamentals(list_of_str[tickers]) --> DataFrame[fundamentals]\n",
    "\n",
    "# '''\n",
    "\n",
    "stock_list = pd.read_csv('optionablestocks.csv')['OPTION SYMBOL'].tolist()\n",
    "stock_list = list(set(tickers[3:] + stock_list))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def pull_data(ticker):\n",
    "    yahoo_data = yahoo_query(ticker,dt.datetime(2018,1,1))\n",
    "    yahoo_data.full_info_query()\n",
    "    earnings_info = yahoo_data.earnings_history.join(yahoo_data.cashFlowStatementQuarter).join(yahoo_data.incomeStatementQuarter.drop(['netIncome','maxAge'],\n",
    "                                                                                                                                      axis = 1),\n",
    "                                                                                               rsuffix='_income').join(yahoo_data.balanceSheetQuarter,\n",
    "                                                                                                                       rsuffix = '_balance')\n",
    "#     earnings_info['earnBeatsBefore'] = 0\n",
    "#     earnings_info['earnMissBefore'] = 0\n",
    "\n",
    "#     for idx, row in earnings_info.iterrows():\n",
    "#         earnings_info.loc[idx,'earnBeatsBefore'] = len(earnings_info[(earnings_info.index <= idx) & (earnings_info.epsDifference > 0)])\n",
    "#         earnings_info.loc[idx,'earnMissBefore'] = len(earnings_info[(earnings_info.index <= idx) & (earnings_info.epsDifference <= 0)])\n",
    "#     earnings_info = earnings_info.shift(1)\n",
    "\n",
    "\n",
    "#     earnings_moves = past_earnings(ticker).sort_index()\n",
    "#     earnings_moves = earnings_moves[(earnings_moves.index > min(yahoo_data.earnings_history.index) - dt.timedelta(days = 92)) &\n",
    "#                                     (earnings_moves.index <= max(yahoo_data.earnings_history.index))].sort_index()\n",
    "\n",
    "\n",
    "#     earnings_df = pd.concat([earnings_info.reset_index(), \n",
    "#                              earnings_moves.reset_index()], axis = 1)\n",
    "    earnings_info.columns = ['quarter' if col == 'index' else col for col in earnings_info.columns.tolist()]\n",
    "    earnings_info['Underlying'] = ticker\n",
    "\n",
    "    ### separate df for current key measures\n",
    "    keyMetrics = yahoo_data.profile.join(yahoo_data.keyStats).join(yahoo_data.finData, rsuffix = '_finData')\n",
    "\n",
    "    return (earnings_info, keyMetrics)\n",
    "\n",
    "def download_yahoo_data(ticker_list, retries = 10):\n",
    "\n",
    "    earnings_lst = []\n",
    "    keyStats_lst = []\n",
    "\n",
    "    item_counter = 0\n",
    "    total_length = len(ticker_list)\n",
    "    failed_list = []\n",
    "\n",
    "    for ticker in ticker_list:\n",
    "        try:\n",
    "            curr_earnings, curr_keyStats = pull_data(ticker)\n",
    "            earnings_lst.append(curr_earnings)\n",
    "            keyStats_lst.append(curr_keyStats)\n",
    "            print('Accepted: {}'.format(ticker))\n",
    "        except:\n",
    "            for i in range(retries):\n",
    "                try:\n",
    "                    curr_earnings, curr_keyStats = pull_data(ticker)\n",
    "                    earnings_lst.append(curr_earnings)\n",
    "                    keyStats_lst.append(curr_keyStats)\n",
    "                    print('Accepted: {}'.format(ticker))\n",
    "                except:\n",
    "                    continue\n",
    "            print('Failed: {}'.format(ticker))\n",
    "            failed_list.append(ticker)\n",
    "\n",
    "        item_counter += 1\n",
    "        print('{0:.2f}% Completed'.format(item_counter/total_length*100))\n",
    "        print('{} total failures'.format(len(failed_list)))\n",
    "\n",
    "    earnings_df = pd.concat(earnings_lst, axis = 0)\n",
    "    #earnings_df = earnings_df.reset_index()[earnings_df.columns]\n",
    "    keyStats_df = pd.concat(keyStats_lst, axis = 0)\n",
    "\n",
    "    return earnings_df, keyStats_df, failed_list\n",
    "\n",
    "def fin_ratios(earnings_df):\n",
    "\n",
    "    ratios_df = earnings_df[['Underlying','timestamp','quarter','1Year', '1month', '3month', '6month', \n",
    "                             'PostEarningsReturn','industry', 'sector']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earnings, ks, failed_list = download_yahoo_data(stock_list, retries = 10)\n",
    "# earnings = earnings.drop(earnings.isnull().sum().sort_values().tail(13).index.tolist(), axis = 1)\n",
    "# earnings.to_csv('full_data.csv')\n",
    "\n",
    "earnings_pct = []\n",
    "for name in earnings.Underlying.drop_duplicates().tolist():\n",
    "    pct = earnings[earnings['Underlying'] == name].sort_index()\n",
    "    pct[pct.columns.tolist()[1:]] = pct[pct.columns.tolist()[1:]].pct_change()\n",
    "    earnings_pct.append(pct.tail(len(pct)-1))\n",
    "\n",
    "earnings_pct = pd.concat(earnings_pct, axis = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Checking Key Stats on Single Names\n",
    "- For each industry filter names that have:\n",
    "1. positive earnings growth\n",
    "2. positive profit margin\n",
    "3. lower than industry average p/b, p/e, ev/ebitda, debt/equity\n",
    "4. rising margins quarter over quarter\n",
    "5. decreasing debt/equity quarter over quarter\n",
    "6. decreasing days of sales outstanding\n",
    "7. lower than industry average inventory/revenue ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Leaps Filtering.xlsx'\n",
    "\n",
    "ks = pd.read_excel(filename, sheetname = 'keystats', index_col = 0).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating average industry values\n",
    "#ks.drop('industry',axis = 1).groupby('sector').mean().to_excel(writer, sheet_name = 'x1')\n",
    "\n",
    "book = load_workbook(filename)\n",
    "writer = pd.ExcelWriter(filename, engine='openpyxl') \n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "ks.drop('industry',axis = 1).groupby('sector').mean().to_excel(writer, \"keystatsAvg\")\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "earnings = pd.read_csv('earningsHist_unshifted.csv', index_col = 0).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating custom columns for value check\n",
    "# Building score for checking\n",
    "\n",
    "score_cols = ['52WeekChange', 'earningsGrowth',\n",
    "              'earningsQuarterlyGrowth', 'forwardPE',\n",
    "              'grossMargins', 'grossProfits',\n",
    "              'pegRatio', 'profitMargins', \n",
    "              'returnOnAssets',\n",
    "              'returnOnEquity', 'revenueGrowth', 'sector']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "earnings.quarter = pd.to_datetime(earnings.quarter)\n",
    "earnings = earnings.groupby(['Underlying','quarter']).sum().reset_index()\n",
    "ticker = 'A'\n",
    "latest_earnings = []\n",
    "for ticker in earnings.Underlying.drop_duplicates().tolist():\n",
    "    latest_earnings.append(earnings[earnings['Underlying'] == ticker][earnings.quarter == max(earnings[earnings['Underlying'] == ticker].quarter)])\n",
    "latest_earnings = pd.concat(latest_earnings, axis = 0)\n",
    "latest_earnings.index = latest_earnings.Underlying\n",
    "\n",
    "earn_cols = ['quarter', '1Year', '1month', '3month', '6month','totalLiab',\n",
    "             'totalStockholderEquity','netIncome',\n",
    "             'operatingIncome',\n",
    "             'totalRevenue','dividendsPaid',\n",
    "             'investments',\n",
    "             'longTermInvestments',\n",
    "             'shortTermInvestments']\n",
    "\n",
    "latest_earnings = latest_earnings[earn_cols]\n",
    "\n",
    "\n",
    "ks = ks[score_cols]\n",
    "\n",
    "names = ks.join(latest_earnings).drop_duplicates()\n",
    "\n",
    "names['dividendsPaid'] = -names['dividendsPaid']\n",
    "\n",
    "names['payoutRatio'] = names.dividendsPaid/names.netIncome\n",
    "names['debtEquityRatio'] = names.totalLiab/names.totalStockholderEquity\n",
    "names['netMargin'] = names.netIncome/names.totalRevenue\n",
    "names['roic'] = names.operatingIncome/(names.longTermInvestments + names.shortTermInvestments)\n",
    "\n",
    "names = names[['debtEquityRatio',\n",
    "       '52WeekChange','earningsGrowth',\n",
    "       'earningsQuarterlyGrowth', 'forwardPE',\n",
    "       'grossMargins', 'grossProfits',\n",
    "       'pegRatio', 'profitMargins', \n",
    "       'returnOnAssets',\n",
    "       'returnOnEquity', 'revenueGrowth', 'sector']]\n",
    "\n",
    "names = names[names['52WeekChange'] != 'Infinity']\n",
    "names['52WeekChange'] = pd.to_numeric(names['52WeekChange'])\n",
    "\n",
    "removes = pd.DataFrame(names.isnull().sum(axis = 1).sort_values(ascending = False))\n",
    "removes = removes[removes[0] <= 3]\n",
    "\n",
    "names = names[names.index.isin(removes.index.tolist())].fillna(0)\n",
    "\n",
    "names_mean = names.groupby('sector').mean()\n",
    "names_mean = names[['sector']].join(names_mean, on = 'sector')\n",
    "\n",
    "names_high = names.groupby('sector').max()\n",
    "names_high = names[['sector']].join(names_high, on = 'sector')\n",
    "\n",
    "names_low = names.groupby('sector').min()\n",
    "names_low = names[['sector']].join(names_low, on = 'sector')\n",
    "\n",
    "names_std = names.groupby('sector').std()\n",
    "names_std = names[['sector']].join(names_std, on = 'sector')\n",
    "\n",
    "del names['sector'], names_mean['sector'], names_high['sector'], names_low['sector'], names_std['sector']\n",
    "\n",
    "score = (names - names_mean)/names_std#(names_high - names_low)\n",
    "\n",
    "del score['forwardPE']\n",
    "\n",
    "score['score'] = ((score['52WeekChange'])/3 -\n",
    "                   (score['debtEquityRatio'] + score['pegRatio'])/3 +\n",
    "                   (score['earningsGrowth'] + score['revenueGrowth'])/3)\n",
    "score.join(ks[['sector']]).sort_values('score',ascending = False).to_csv('leaps_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
