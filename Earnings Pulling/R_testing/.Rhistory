<<<<<<< HEAD
View(test_y_actual)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
cm = table(test_y_actual[2:ncol(test_y_actual)], y_pred > 0.5)
cm = table(test_y_actual[2:ncol(test_y_actual)], y_pred)
cm = table(test_y_actual[c('down','flat','up')], y_pred)
cm = table(test_y_actual[,c('down','flat','up')], y_pred)
y_pred = data.frame(ifelse(prob_pred > 0.7, 1, 0))
cm = table(test_y_actual[,c('down','flat','up')], y_pred)
cm = table(as.data.frame(table(test_y_actual[,c('down','flat','up')])),
as.data.frame(table(y_pred)))
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
cm
1155+71+510+103
613*3
model.grid(x.vars)
model.grid(columns)
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
expand.grid(n.list)
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
model.grid(1)
model.grid(5)
model.grid(length(columns))
x = train
length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) x.vars[x]) %>%
.[2:dim(model.grid(length(x.vars)))[1]]
library(purrr)
library(magrittr)
length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) x.vars[x]) %>%
.[2:dim(model.grid(length(x.vars)))[1]]
length(columns)^2
columns
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) x.vars[x]) %>%
.[2:dim(model.grid(length(x.vars)))[1]]
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) x.vars[x]) %>%
.[2:dim(model.grid(length(x.vars)))[1]] %>%
as.data.frame()
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) x.vars[x]) %>%
.[2:dim(model.grid(length(x.vars)))[1]]
best_set = data.frame(best_set)
=======
glm.pred = rep("No", length(glm.probs))
glm.pred[glm.probs > .5] = "Yes"
# iv.
table(glm.pred, test.Y)
(142+19)/(5854+142+19+66
)
mean(glm.pred != test.Y)
set.seed(1)
x = rnorm(100)
epsilon = rnorm(100)
b0 = 1
b1 = 2
b2 = 3
b3 = 4
y = b0 + b1*x + b2*x^2 + b3*x^3 + epsilon
plot(x, y)
library(leaps)
regfit.full = regsubsets(y~., data = data.frame(poly(x, 10), y), nvmax = 10)
install.packages(leaps)
install.packages('leaps')
library(leaps)
reg.summary = summary(regfit.full)
regfit.full = regsubsets(y~., data = data.frame(poly(x, 10), y), nvmax = 10)
reg.summary = summary(regfit.full)
par(mfrow = c(2,2))
plot(reg.summary$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")
points(which.min(reg.summary$rss), min(reg.summary$rss), col = "red", cex = 2, pch = 20)
plot(reg.summary$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")
plot(reg.summary$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")
points(which.min(reg.summary$rss), min(reg.summary$rss), col = "red", cex = 2, pch = 20)
install.packages('glmnet')
library(glmnet)
library(glmnet)
xmat = model.matrix(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6) + I(x^7) + I(x^8) + I(x^9) + I(x^10), data = data.full)[, -1]
data.full = data.frame(y = y, x = x)
regfit.full = regsubsets(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6) + I(x^7) + I(x^8) + I(x^9) + I(x^10), data = data.full, nvmax = 10)
reg.summary = summary(regfit.full)
xmat = model.matrix(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6) + I(x^7) + I(x^8) + I(x^9) + I(x^10), data = data.full)[, -1]
cv.lasso = cv.glmnet(xmat, y, alpha = 1)
plot(cv.lasso)
library(ISLR)
attach(Smarket)
summary(Smarket)
train = (Year < 2005)
?hatvalues
??hatvalues
# Logistic Regression
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
library(lubridate)
library(dplyr)
library(nnet)
library(kable)
<<<<<<< HEAD
library(purrr)
library(magrittr)
dataset = read.csv('earnings_data.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
=======
setwd("C:/Users/fchen/Desktop/Python Trading/SPX-Put-Selling/Live Data Pulling/Earnings Pulling")
install.packages('kable')
library(purrr)
library(magrittr)
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
View(dataset)
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-03-31'))
train = train[,columns]
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
<<<<<<< HEAD
=======
# Splitting the dataset into the Training set and Test set
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
train = dataset %>%
filter(quarter < as.Date('2018-03-31'))
train = train[,columns]
test = dataset %>%
<<<<<<< HEAD
filter(quarter >= as.Date('2018-03-31')) %>%
filter(quarter < as.Date('2018-05-31'))
test = test[,columns]
valid = dataset %>%
filter(quarter >= as.Date('2018-05-31'))
valid = valid[,columns]
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) x.vars[x]) %>%
.[2:dim(model.grid(length(x.vars)))[1]]
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
best_set[1:5]
print(set)
for (set in best_set[1:5]) {
print(set)
}
for (set in best_set[1:5]) {
print(paste0('retur_factor', " ~ ", paste(x, collapse = "+")))
}
for (set in best_set[1:5]) {
print(paste0('retur_factor', " ~ ", paste(set, collapse = "+")))
}
for (set in best_set[1:5]) {
multinom(paste0('retur_factor', " ~ ", paste(set, collapse = "+")),
data = train)
}
for (set in best_set[1:5]) {
multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
}
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
classifier = multinom(return_factor ~ ., data = train)
stderrors = t(summary(classifier)$standard.errors)
prob_pred = predict(classifier, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
write.csv(y_pred,'preds')
write.csv(test_y_actual,'actuals.csv')
write.csv(y_pred,'preds.csv')
cm
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
cm
cm[2,2]
cbind(correct_ests = cm[2,2],correct_ests = cm[2,2])
cm[2,2][0]
cm[2,2]
int(cm[2,2])
unlist(cm[2,2])
cbind(unlist(cm[2,2]),unlist(cm[2,2]))
cm
cm$1[[2]]
cm[2,2].value
cm[2,2]
cbind(cm[2,2])
ests = c()
ests + 1
ests + c(1)
ests
ests
ests = c()
i = 1
for (set in best_set[1:5]) {
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
ests[[i]] = cm[2,2]
i = i + 1
}
cm
ests
ests = list()
i = 1
for (set in best_set[1:5]) {
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
ests[[i]] = cm[2,2]
i = i + 1
}
ests
set
for (set in best_set[1:5]) {
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
result = tryCatch(
{cm[2,2]},
error = function(cond) {
return(0)
}
)
ests[[i]] = result
i = i + 1
}
dataset = read.csv('earnings_data.csv')
=======
filter(quarter >= as.Date('2018-03-31'))
test = test[,columns]
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
View(dataset)
colnames(dataset)
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
View(dataset)
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
<<<<<<< HEAD
train = dataset %>%
filter(quarter < as.Date('2018-03-31'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-03-31')) %>%
filter(quarter < as.Date('2018-05-31'))
test = test[,columns]
valid = dataset %>%
filter(quarter >= as.Date('2018-05-31'))
valid = valid[,columns]
=======
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
valid = dataset %>%
filter(quarter >= as.Date('2018-05-31'))
View(valid)
View(valid)
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
<<<<<<< HEAD
=======
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
ests = list()
i = 1
<<<<<<< HEAD
for (set in best_set[1:5]) {
=======
for (set in best_set) {
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
result = tryCatch(
{cm[2,2]},
error = function(cond) {
return(0)
<<<<<<< HEAD
}
)
ests[[i]] = result
i = i + 1
}
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Logistic Regression
library(lubridate)
library(dplyr)
library(nnet)
library(kable)
library(purrr)
library(magrittr)
# Importing the dataset
dataset = read.csv('earnings_data.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
=======
}
)
ests[[i]] = result
i = i + 1
}
View(best_set)
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
View(dataset)
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
View(dataset)
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
dataset$quarter = as.Date(dataset$quarter, "%Y-%m-%d")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%Y-%m-%d")
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
ests = list()
i = 1
for (set in best_set) {
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
result = tryCatch(
{cm[2,2]},
error = function(cond) {
return(0)
}
)
ests[[i]] = result
i = i + 1
}
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%Y-%m-%d")
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
test_y_actual = data.frame(test$return_factor)
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
View(dataset)
dataset$quarter = as.Date(dataset$quarter, "%Y-%m-%d")
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
View(test_y_actual)
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
ests = list()
i = 1
for (set in best_set) {
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
result = tryCatch(
{cm[2,2]},
error = function(cond) {
return(0)
}
)
ests[[i]] = result
i = i + 1
}
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%Y-%m-%d")
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
train = train[,columns]
test = test[,columns]
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
ests = list()
i = 1
for (set in best_set) {
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
result = tryCatch(
{cm[2,2]},
error = function(cond) {
return(0)
}
)
ests[[i]] = result
i = i + 1
}
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%Y-%m-%d")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
<<<<<<< HEAD
valid = dataset %>%
filter(quarter >= as.Date('2018-05-31'))
valid = valid[,columns]
=======
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
<<<<<<< HEAD
# function for best subset regression
=======
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
ests = list()
i = 1
for (set in best_set) {
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
result = tryCatch(
{cm[2,2]},
error = function(cond) {
return(0)
}
)
ests[[i]] = result
i = i + 1
}
<<<<<<< HEAD
ests
max(ests)
max(unlist(ests))
which(unlist(ests)==max(unlists(ests)))
which(unlist(ests)==max(unlists(ests)))
which(unlist(ests)==max(unlist(ests)))
ests_array = unlist(ests)
ests_array
which(ests_array == max(ests_array))
ests_array[10725]
ests_array[11621]
best_set[10725]
best_est[11621]
best_ests[11621]
best_set[11621]
load("C:/Users/Fang/Desktop/Python Trading/SPX Option Backtester/SPX Put Selling/Live Data Pulling/Earnings Pulling/earnings_env.RData")
library(lubridate)
library(dplyr)
library(nnet)
library(purrr)
library(magrittr)
out
ests
which(unlist(ests) == max(unlist(ests)))
best_set[which(unlist(ests) == max(unlist(ests)))]
factors = best_set[which(unlist(ests) == max(unlist(ests)))]
factors
factors
unlist(factors)
unique(unlist(factors))
top_factors = unique(unlist(factors))
columns = c("industry","current_ratio","total_debt_equity_ratio",
"gross_margin","changeToLiabilities","changeToNetincome",
"changeToOperatingActivities","operating_margin","interest_coverage_ratio",
"net_profit_margin","X1Year","day_sales_outstanding","roe")
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
columns = c("industry","current_ratio","total_debt_equity_ratio",
"gross_margin","changeToLiabilities","changeToNetincome",
"changeToOperatingActivities","operating_margin","interest_coverage_ratio",
"net_profit_margin","X1Year","day_sales_outstanding","roe")
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
ests = list()
i = 1
for (set in best_set) {
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
result = tryCatch(
{cm[2,2]},
error = function(cond) {
return(0)
}
)
ests[[i]] = result
i = i + 1
}
columns = c("industry","current_ratio","total_debt_equity_ratio",
"gross_margin","changeToLiabilities","changeToNetincome",
"changeToOperatingActivities","operating_margin","interest_coverage_ratio",
"net_profit_margin","X1Year","day_sales_outstanding","roe",'return_factor')
=======
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
<<<<<<< HEAD
=======
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
ests = list()
i = 1
for (set in best_set) {
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
result = tryCatch(
{cm[2,2]},
error = function(cond) {
return(0)
}
)
ests[[i]] = result
i = i + 1
}
ests
<<<<<<< HEAD
max(ests)
max(unlist(ests))
which(unlist(ests) == max(unlist(ests)))
best_ests[which(unlist(ests) == max(unlist(ests)))]
best_set[which(unlist(ests) == max(unlist(ests)))]
View(train)
best_set[which(unlist(ests) == max(unlist(ests)))]
best_set[5]
best_set[which(unlist(ests) == max(unlist(ests)))]
which(unlist(ests) == max(unlist(ests)))[5]
best_set[3709]
best_set[3709]
unlist(best_set[3709])
paste0('return_factor', " ~ ", paste(unlist(best_set[3709]), collapse = "+")
)
classifier = multinom(paste0('return_factor', " ~ ", paste(unlist(best_set[3709]), collapse = "+"),
data = train))
View(train)
classifier = multinom(paste0('return_factor', " ~ ", paste(unlist(best_set[3709]), collapse = "+"),
data = train))
View(train)
best_set[3709]
train[best_set[3709]]
train[unlist(best_set[3709])]
unlist(best_set[3709])
unlist(best_set[3709]) + c('return_factor')
unlist(best_set[3709]) + 'return_factor'
c(unlist(best_set[3709]), 'return_factor')
data = dataset[c(unlist(best_set[3709]), 'return_factor')]
data = dataset[c(unlist(best_set[3709]), 'return_factor', 'quarter')]
train = data %>%
filter(quarter < as.Date('2018-04-30'))
test = data %>%
filter(quarter >= as.Date('2018-04-30'))
View(test)
data = dataset[c(unlist(best_set[3709]), 'return_factor','quarter')]
train = data %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,c(unlist(best_set[3709]), 'return_factor')]
test = data %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,c(unlist(best_set[3709]), 'return_factor')]
View(test)
classifier = multinom(return_factor ~. ,
data = train)
stderrors = t(summary(classifier)$standard.errors)
prob_pred = predict(classifier, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
correct_ests = cm[2,2]
correct_ests
cm
stderrors
summary(classifier)
write.csv(summary(classifier),'model.csv')
prob_pred = predict(classifier, test, "probs")
y_pred = ifelse(prob_pred > 0.5, 1, 0)
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
correct_ests = cm[2,2]
prob_pred = predict(classifier, test, "probs")
y_pred = ifelse(prob_pred > 0.3, 1, 0)
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
correct_ests = cm[2,2]
cm
prob_pred = predict(classifier, test, "probs")
y_pred = ifelse(prob_pred > 0.25, 1, 0)
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
correct_ests = cm[2,2]
correct_ests
cm
View(y_pred)
write.csv(test,'test_data.csv')
write.csv(y_pred,'test_pred.csv')
prob_pred = predict(classifier, test, "probs")
y_pred = ifelse(prob_pred > 0.5, 1, 0)
write.csv(y_pred,'test_pred.csv')
write.csv(y_pred,'test_pred.csv')
=======
which(ests == max(ests))
ests_array = unlist(ests)
which(ests_array == max(ests_array))
which(ests_array == max(ests_array))[0]
ests_array[14428]
ests_array[14556]
best_set[14556]
best_set[which(ests_array == max(ests_array))]
save.image("C:/Users/fchen/Desktop/Python Trading/SPX-Put-Selling/Live Data Pulling/Earnings Pulling/earnings_env.RData")
>>>>>>> f5b8fcbead30ada3dd465217ae0b00df40f1513a
