{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. dividend growth twice the rate of inflation over last 3 years\n",
    "2. flat or declinging payout ratio over last 3 years\n",
    "    - Payout Ratio = (Dividends per Share (DPS) / Earnings per Share (EPS)) x 100\n",
    "    - Payout Ratio = (Total Dividends Paid / Net Income) x 100\n",
    "3. 3 year average payout ratio less than 60%\n",
    "4. debt to equity ratio under 1.5\n",
    "    - Debt/Equity Ratio = Total Liabilities / Shareholders' Equity\n",
    "5. maintain net margins over 7% \n",
    "    - Net Margin = Net Income / Total Revenues\n",
    "6. ROIC level exceeds 20%\n",
    "    - Net Operating Profit After Tax (NOPAT)/Invested Capital = ROIC\n",
    "7. decreasing diluted share count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note to import from .py files, must follow structure\n",
    "# from <.py filename excluding '.py'> import <class name>\n",
    "# Optionslam creds: aspringfastlaner Options2018\n",
    "\n",
    "# Importing necessary models\n",
    "import smtplib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas.stats.moments as st\n",
    "from pandas import ExcelWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as dates\n",
    "# import matplotlib.ticker as ticker\n",
    "from lxml import html\n",
    "import requests\n",
    "import webbrowser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import csv\n",
    "import sched, time\n",
    "import pandas_datareader as datareader\n",
    "from pandas_datareader.data import Options\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "import urllib.request as req\n",
    "import pandas_market_calendars as mcal\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "from helpers import *\n",
    "\n",
    "import py_vollib\n",
    "from py_vollib.black_scholes_merton.implied_volatility import *\n",
    "from py_vollib.black_scholes_merton.greeks.analytical import *\n",
    "import plotly\n",
    "import os\n",
    "\n",
    "\n",
    "from scipy.stats import norm as norm\n",
    "from yahoo_query import *\n",
    "\n",
    "# Alpha Vantage API Key\n",
    "# 5HZEUI5AFJB06BUK\n",
    "\n",
    "# ts = TimeSeries(key='5HZEUI5AFJB06BUK', output_format='pandas')\n",
    "# data, meta_data = ts.get_intraday(symbol='MSFT',interval='1min', outputsize='full')\n",
    "# data['close'].plot()\n",
    "# plt.title('Intraday Times Series for the MSFT stock (1 min)')\n",
    "# For intraday\n",
    "# https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=MSFT&interval=1min&apikey=d5HZEUI5AFJB06BUK&datatype=csv\n",
    "\n",
    "# For daily\n",
    "# https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=MSFT&apikey=5HZEUI5AFJB06BUK&datatype=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# functions list:\n",
    "\n",
    "#     maturities(dt.datetime()) --> [float(front_wgt), float(back_wgt)]\n",
    "\n",
    "#     optionslam_scrape(str[ticker]) --> dict[earnings]\n",
    "\n",
    "#     yahoo_table_parse(str[raw_html_table]) --> DataFrame[ticker]\n",
    "\n",
    "#     yahoo_earnings(dt.datetime()) --> DataFrame[earnings_on_date]\n",
    "\n",
    "#     fundamentals(str[ticker]) --> DataFrame[stock_fundamentals]\n",
    "\n",
    "#     get_fundas(list[ticker_lst]) --> DataFrame[stock_fundamentals]\n",
    "\n",
    "#     historical_data(str[ticker], int[day_number], int[rolling_window], outsize[str]) --> DataFrame[daily_stock_data]\n",
    "\n",
    "#     current_volatility(list[ticker_lst], int[roll]) --> DataFrame[stock_volatilities]\n",
    "\n",
    "#     all_options(str[ticker], bool[greeks]) --> DataFrame[options_chains]\n",
    "\n",
    "#     earnings_condor(str[ticker], int[max_gap], int[dte_thresh], float[|money_thresh| <= 1]) -- DataFrame[condors], DataFrame[puts], DataFrame[calls]\n",
    "\n",
    "#     write_excel(str[filename], list[str[sheetnames]], list[dataframes]) --> void()\n",
    "\n",
    "#     curr_stock_data(str[ticker]) --> DataFrame[stock_info]\n",
    "\n",
    "#     curr_batch_quotes(list_of_string[tickers]) --> DataFrame[stock_info]\n",
    "\n",
    "#     past_earnings(str[ticker]) --> DataFrame[earnings_info]\n",
    "\n",
    "#     earnings_history(str[ticker]) --> [DataFrame[earnings_estimate], DataFrame[past_earnings], DataFrame[earnings_estimate_change]]\n",
    "\n",
    "#     av_data(str[ticker]) --> DataFrame[ticker_open, ticker_close]\n",
    "\n",
    "#     av_batch(list_of_str[tickers]) --> DataFrame[tickers_closes]\n",
    "\n",
    "#     check_mkt_corr(int[corr_rolling_window],int[plot_window]) --> DataFrame[rolling_corr]\n",
    "\n",
    "#     vvix_check() --> DataFrame[VVIX Data]\n",
    "\n",
    "#     earnings_longs(list_of_str[ticker], float[bid_ask_spread]) --> DataFrame[option_chains]\n",
    "\n",
    "#     all_options_v2(str[ticker], int[dte_ub], int[dte_lb], float[moneyness]) --> DataFrame[option_chains]\n",
    "\n",
    "#     yahoo_options_query(str[ticker], int[dte_ub], int[dte_lb]) --> DataFrame[option_chains]\n",
    "\n",
    "#     greek_calc(DataFrame[option_chain], str[prem_price_use], str[day_format], float[interest_rate], float[dividend_rate])\n",
    "\n",
    "#     price_sim(DataFrame[options_df], float[price_change], float[vol_change], int[days_change], str[output = 'All'],\n",
    "#               str[skew = 'flat'], str[day_format = 'trading'], float[interest_rate = 0.0193], float[dividend_rate = 0],\n",
    "#               float[prem_price_use = 'Mid'])\n",
    "\n",
    "\n",
    "#     position_sim(DataFrame[position_df], list_of_int[holdings], int[shares],\n",
    "#                  float[price_change], float[vol_change], int[dte_change], str[output = 'All'],\n",
    "#                  str[skew = 'flat'], str[prem_price_use = 'Mid'], str[day_format = 'trading'], \n",
    "#                  float[interest_rate = 0.0193], float[dividend_rate = 0])\n",
    "\n",
    "#     yahoo_fundamentals(list_of_str[tickers]) --> DataFrame[fundamentals]\n",
    "\n",
    "# '''\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\Fang\\\\Desktop\\\\Python Trading\\\\Single Name Testing\\\\Single-Name-Testing\\\\Names')\n",
    "\n",
    "tsx = pd.read_table('TSX.txt')\n",
    "tsxv = pd.read_table('TSXV.txt')\n",
    "amex = pd.read_table('AMEX.txt')\n",
    "nasdaq = pd.read_table('NASDAQ.txt')\n",
    "nyse = pd.read_table('NYSE.txt')\n",
    "\n",
    "us_names = pd.concat([amex,nasdaq, nyse], axis = 0)[['Symbol']].drop_duplicates()\n",
    "cad_names = pd.concat([tsx,tsxv], axis = 0)[['Symbol']].drop_duplicates()\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\Fang\\\\Desktop\\\\Python Trading\\\\Single Name Testing\\\\Single-Name-Testing\\\\DGI Pulling')\n",
    "\n",
    "stock_list = pd.read_csv('companylist.csv')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def pull_data(ticker):\n",
    "    yahoo_data = yahoo_query(ticker,dt.datetime(2018,1,1))\n",
    "    yahoo_data.full_info_query()\n",
    "    \n",
    "    def create_dgi(balanceSheet, incomeStatement, cashFlowStatement):\n",
    "        dgi_data = balanceSheet[['totalLiab',\n",
    "                                 'totalStockholderEquity',\n",
    "                                 'longTermInvestments',\n",
    "                                 'shortTermInvestments']]\n",
    "        \n",
    "        dgi_data = dgi_data.join(incomeStatement[['netIncome',\n",
    "                                                  'operatingIncome',\n",
    "                                                  'totalRevenue']])\n",
    "        \n",
    "        dgi_data = dgi_data.join(cashFlowStatement[['dividendsPaid',\n",
    "                                                    'investments']])\n",
    "        dgi_data['dividendsPaid'] = -dgi_data['dividendsPaid']\n",
    "\n",
    "        dgi_data['payoutRatio'] = dgi_data.dividendsPaid/dgi_data.netIncome\n",
    "        dgi_data['debtEquityRatio'] = dgi_data.totalLiab/dgi_data.totalStockholderEquity\n",
    "        dgi_data['netMargin'] = dgi_data.netIncome/dgi_data.totalRevenue\n",
    "        dgi_data['roic'] = dgi_data.operatingIncome/(dgi_data.longTermInvestments + dgi_data.shortTermInvestments)\n",
    "        \n",
    "        dgi_data = dgi_data[['payoutRatio','debtEquityRatio','netMargin','roic','dividendsPaid']]\n",
    "        dgi_data['Underyling'] = ticker\n",
    "        return dgi_data\n",
    "    \n",
    "    dgi_annual = create_dgi(yahoo_data.balanceSheetAnnual, yahoo_data.incomeStatementAnnual, \n",
    "                            yahoo_data.cashFlowStatementAnnual)\n",
    "\n",
    "    ### separate df for current key measures\n",
    "    keyMetrics = yahoo_data.profile.join(yahoo_data.keyStats).join(yahoo_data.finData, rsuffix = '_finData')\n",
    "    \n",
    "    return (dgi_annual, keyMetrics)\n",
    "\n",
    "def download_yahoo_data(ticker_list, retries = 10, lookback_years = 3):\n",
    "\n",
    "    earnings_lst = []\n",
    "    keyStats_lst = []\n",
    "    dgi_lst = []\n",
    "\n",
    "    item_counter = 0\n",
    "    total_length = len(ticker_list)\n",
    "    failed_list = []\n",
    "\n",
    "    for ticker in ticker_list:\n",
    "        try:\n",
    "            curr_earnings, curr_keyStats = pull_data(ticker)\n",
    "            earnings_lst.append(curr_earnings)\n",
    "            keyStats_lst.append(curr_keyStats)\n",
    "            \n",
    "            dgi_df = curr_earnings[['Underyling']]#pd.DataFrame(index = [ticker])\n",
    "            dgi_df['quarter'] = pd.to_datetime(curr_earnings.index)\n",
    "            dgi_df['payoutChange'] = curr_earnings.payoutRatio.sort_index().pct_change().tail(lookback_years).mean()\n",
    "            dgi_df['divGrowth'] = curr_earnings.dividendsPaid.sort_index().pct_change().tail(lookback_years).mean()\n",
    "            dgi_df['payoutAvg'] = curr_earnings.payoutRatio.sort_index().tail(lookback_years).mean()\n",
    "            dgi_df['debtEquityAvg'] = curr_earnings.debtEquityRatio.sort_index().tail(lookback_years).mean()\n",
    "            dgi_df['netMarginAvg'] = curr_earnings.netMargin.sort_index().tail(lookback_years).mean()\n",
    "            dgi_df['roicAvg'] = curr_earnings.roic.sort_index().tail(lookback_years).mean()\n",
    "\n",
    "            dgi_lst.append(dgi_df)\n",
    "            print('Accepted: {}'.format(ticker))\n",
    "        except:\n",
    "            for i in range(retries):\n",
    "                try:\n",
    "                    curr_earnings, curr_keyStats = pull_data(ticker)\n",
    "                    earnings_lst.append(curr_earnings)\n",
    "                    keyStats_lst.append(curr_keyStats)\n",
    "                    \n",
    "                    dgi_df = curr_earnings[['Underyling']] # pd.DataFrame(index = [ticker])\n",
    "                    dgi_df['quarter'] = pd.to_datetime(curr_earnings.index)\n",
    "                    dgi_df['payoutChange'] = curr_earnings.payoutRatio.sort_index().pct_change().tail(lookback_years).mean()\n",
    "                    dgi_df['divGrowth'] = curr_earnings.dividendsPaid.sort_index().pct_change().tail(lookback_years).mean()\n",
    "                    dgi_df['payoutAvg'] = curr_earnings.payoutRatio.sort_index().tail(lookback_years).mean()\n",
    "                    dgi_df['debtEquityAvg'] = curr_earnings.debtEquityRatio.sort_index().tail(lookback_years).mean()\n",
    "                    dgi_df['netMarginAvg'] = curr_earnings.netMargin.sort_index().tail(lookback_years).mean()\n",
    "                    dgi_df['roicAvg'] = curr_earnings.roic.sort_index().tail(lookback_years).mean()\n",
    "\n",
    "                    dgi_lst.append(dgi_df)\n",
    "                    print('Accepted: {}'.format(ticker))\n",
    "                except:\n",
    "                    continue\n",
    "            print('Failed: {}'.format(ticker))\n",
    "            failed_list.append(ticker)\n",
    "\n",
    "        item_counter += 1\n",
    "        print('{0:.2f}% Completed'.format(item_counter/total_length*100))\n",
    "        print('{} total failures'.format(len(failed_list)))\n",
    "    try:\n",
    "        earnings_df = pd.concat(earnings_lst, axis = 0)\n",
    "        # earnings_df = earnings_df.reset_index()[earnings_df.columns]\n",
    "        keyStats_df = pd.concat(keyStats_lst, axis = 0)\n",
    "        dgi_df = pd.concat(dgi_lst, axis = 0)\n",
    "\n",
    "        return earnings_df, keyStats_df, dgi_df, failed_list\n",
    "    except:\n",
    "        return failed_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: AAB.TO\n",
      "0.03% Completed\n",
      "1 total failures\n",
      "Failed: AAV.TO\n",
      "0.05% Completed\n",
      "2 total failures\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:133: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:135: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\Fang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepted: ABT.TO\n",
      "0.08% Completed\n",
      "2 total failures\n",
      "Failed: ABX.TO\n",
      "0.10% Completed\n",
      "3 total failures\n",
      "Failed: AC.TO\n",
      "0.13% Completed\n",
      "4 total failures\n",
      "Failed: ACB.TO\n",
      "0.15% Completed\n",
      "5 total failures\n",
      "Failed: ACB.WT.TO\n",
      "0.18% Completed\n",
      "6 total failures\n",
      "Failed: ACD.TO\n",
      "0.20% Completed\n",
      "7 total failures\n",
      "Failed: ACO.X.TO\n",
      "0.23% Completed\n",
      "8 total failures\n",
      "Failed: ACO.Y.TO\n",
      "0.26% Completed\n",
      "9 total failures\n",
      "Failed: ACQ.TO\n",
      "0.28% Completed\n",
      "10 total failures\n",
      "Failed: ACR.UN.TO\n",
      "0.31% Completed\n",
      "11 total failures\n",
      "Failed: ACZ.UN.TO\n",
      "0.33% Completed\n",
      "12 total failures\n",
      "Failed: AD.TO\n",
      "0.36% Completed\n",
      "13 total failures\n",
      "Failed: ADC.UN.TO\n",
      "0.38% Completed\n",
      "14 total failures\n",
      "Failed: ADN.TO\n",
      "0.41% Completed\n",
      "15 total failures\n",
      "Failed: ADW.A.TO\n",
      "0.43% Completed\n",
      "16 total failures\n",
      "Failed: ADW.B.TO\n",
      "0.46% Completed\n",
      "17 total failures\n",
      "Failed: AEF.TO\n",
      "0.49% Completed\n",
      "18 total failures\n",
      "Failed: AEF.WT.TO\n",
      "0.51% Completed\n",
      "19 total failures\n",
      "Failed: AEM.TO\n",
      "0.54% Completed\n",
      "20 total failures\n",
      "Failed: AEZS.TO\n",
      "0.56% Completed\n",
      "21 total failures\n",
      "Failed: AFN.TO\n",
      "0.59% Completed\n",
      "22 total failures\n",
      "Failed: AFN.DB.B.TO\n",
      "0.61% Completed\n",
      "23 total failures\n",
      "Failed: AFN.DB.C.TO\n",
      "0.64% Completed\n",
      "24 total failures\n",
      "Failed: AFN.DB.D.TO\n",
      "0.67% Completed\n",
      "25 total failures\n",
      "Failed: AFN.DB.E.TO\n",
      "0.69% Completed\n",
      "26 total failures\n",
      "Failed: AGF.B.TO\n",
      "0.72% Completed\n",
      "27 total failures\n"
     ]
    }
   ],
   "source": [
    "earnings_df, keyStats_df, dgi_df, failed_list = download_yahoo_data(cad_names['Symbol'].tolist(),10, 3)\n",
    "\n",
    "earnings_df.fillna(0).to_csv('cad_dgi_raw.csv')\n",
    "keyStats_df.to_csv('cad_keystats.csv')\n",
    "dgi_df.fillna(0).to_csv('cad_dgi_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filterd_dgi = dgi_df[(dgi_df['debtEquityAvg'] <= 1.5) &\n",
    "       (dgi_df['divGrowth'] >= 0.03) &\n",
    "       (dgi_df['payoutChange'] <= 0) &\n",
    "       (dgi_df['payoutAvg'] <= 0.6) & (dgi_df['payoutAvg'] >= 0) &\n",
    "       (dgi_df['netMarginAvg'] >= 0.07) &\n",
    "       (dgi_df['roicAvg'] >= 0.2)].sort_values('divGrowth', ascending = False)\n",
    "\n",
    "filterd_dgi.to_csv('filtered_dgi_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lookback_years = 3\n",
    "# dgi_list = []\n",
    "\n",
    "# for ticker in earnings_df['Underlying'].drop_duplicates().tolist():\n",
    "#     curr_earnings = earnings_df[earnings_df['Underlying'] == ticker]\n",
    "\n",
    "#     dgi_df = pd.DataFrame(index = [ticker])\n",
    "#     dgi_df['payoutChange'] = curr_earnings.payoutRatio.sort_index().pct_change().tail(lookback_years).mean()\n",
    "#     dgi_df['divGrowth'] = curr_earnings.dividendsPaid.sort_index().pct_change().tail(lookback_years).mean()\n",
    "#     dgi_df['payoutAvg'] = curr_earnings.payoutRatio.sort_index().tail(lookback_years).mean()\n",
    "#     dgi_df['debtEquityAvg'] = curr_earnings.debtEquityRatio.sort_index().tail(lookback_years).mean()\n",
    "#     dgi_df['netMarginAvg'] = curr_earnings.netMargin.sort_index().tail(lookback_years).mean()\n",
    "#     dgi_df['roicAvg'] = curr_earnings.roic.sort_index().tail(lookback_years).mean()\n",
    "#     dgi_list.append(dgi_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
